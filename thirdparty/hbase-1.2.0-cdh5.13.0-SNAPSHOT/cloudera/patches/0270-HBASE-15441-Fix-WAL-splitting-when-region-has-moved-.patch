From 0ec4dbb4250272d8ccb9af94d2bea5a207dcbeee Mon Sep 17 00:00:00 2001
From: Elliott Clark <eclark@apache.org>
Date: Thu, 10 Mar 2016 14:48:57 -0800
Subject: [PATCH 270/362] HBASE-15441 Fix WAL splitting when region has moved
 multiple times

Summary:
Currently WAL splitting is broken when a region has been opened multiple times in recent minutes.

Region open and region close write event markers to the wal. These markers should have the sequence id in them. However it is currently getting 1. That means that if a region has moved multiple times in the last few mins then multiple split log workers will try and create the recovered edits file for sequence id 1. One of the workers will fail and on failing they will delete the recovered edits. Causing all split wal attempts to fail.

We need to:

It appears that the close event with a sequence id of one is coming from region warm up.

This patch fixes that by making sure the close on warm up doesn't happen. Also splitting will ignore any of the events that are already in the logs.

Test Plan: Unit tests pass

Differential Revision: https://reviews.facebook.net/D55557

(cherry picked from commit aaaae834234569b4ff0abc632311fc87d6d7b07f)

Change-Id: I6bd89488feea8f8722ce98925fbc6e293cc22864
Author:    Elliott Clark <eclark@apache.org>
Ref:       CDH-50405
Reason:    Bug
---
 .../apache/hadoop/hbase/protobuf/ProtobufUtil.java |   29 +++++++++++++++++---
 .../apache/hadoop/hbase/regionserver/HRegion.java  |   10 ++++---
 .../hadoop/hbase/regionserver/wal/WALEdit.java     |   14 ++++++----
 .../RegionReplicaReplicationEndpoint.java          |    5 ++++
 .../org/apache/hadoop/hbase/wal/WALSplitter.java   |   24 ++++++++++++++++
 5 files changed, 69 insertions(+), 13 deletions(-)

diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java
index 7609605..6b2fc39 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java
@@ -2687,15 +2687,36 @@ public final class ProtobufUtil {
   public static RegionEventDescriptor toRegionEventDescriptor(
       EventType eventType, HRegionInfo hri, long seqId, ServerName server,
       Map<byte[], List<Path>> storeFiles) {
+    final byte[] tableNameAsBytes = hri.getTable().getName();
+    final byte[] encodedNameAsBytes = hri.getEncodedNameAsBytes();
+    final byte[] regionNameAsBytes = hri.getRegionName();
+    return toRegionEventDescriptor(eventType,
+        tableNameAsBytes,
+        encodedNameAsBytes,
+        regionNameAsBytes,
+        seqId,
+
+        server,
+        storeFiles);
+  }
+
+  public static RegionEventDescriptor toRegionEventDescriptor(EventType eventType,
+                                                              byte[] tableNameAsBytes,
+                                                              byte[] encodedNameAsBytes,
+                                                              byte[] regionNameAsBytes,
+                                                               long seqId,
+
+                                                              ServerName server,
+                                                              Map<byte[], List<Path>> storeFiles) {
     RegionEventDescriptor.Builder desc = RegionEventDescriptor.newBuilder()
         .setEventType(eventType)
-        .setTableName(ByteStringer.wrap(hri.getTable().getName()))
-        .setEncodedRegionName(ByteStringer.wrap(hri.getEncodedNameAsBytes()))
-        .setRegionName(ByteStringer.wrap(hri.getRegionName()))
+        .setTableName(ByteStringer.wrap(tableNameAsBytes))
+        .setEncodedRegionName(ByteStringer.wrap(encodedNameAsBytes))
+        .setRegionName(ByteStringer.wrap(regionNameAsBytes))
         .setLogSequenceNumber(seqId)
         .setServer(toServerName(server));
 
-    for (Map.Entry<byte[], List<Path>> entry : storeFiles.entrySet()) {
+    for (Entry<byte[], List<Path>> entry : storeFiles.entrySet()) {
       StoreDescriptor.Builder builder = StoreDescriptor.newBuilder()
           .setFamilyName(ByteStringer.wrap(entry.getKey()))
           .setStoreHomeDir(Bytes.toString(entry.getKey()));
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
index 4e27ad5..aa14006 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
@@ -965,10 +965,13 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
 
   private void initializeWarmup(final CancelableProgressable reporter) throws IOException {
     MonitoredTask status = TaskMonitor.get().createStatus("Initializing region " + this);
-
     // Initialize all the HStores
     status.setStatus("Warming up all the Stores");
-    initializeStores(reporter, status);
+    try {
+      initializeStores(reporter, status);
+    } finally {
+      status.markComplete("Done warming up.");
+    }
   }
 
   /**
@@ -6497,9 +6500,8 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
       fs = FileSystem.get(conf);
     }
 
-    HRegion r = HRegion.newHRegion(tableDir, wal, fs, conf, info, htd, rsServices);
+    HRegion r = HRegion.newHRegion(tableDir, wal, fs, conf, info, htd, null);
     r.initializeWarmup(reporter);
-    r.close();
   }
 
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java
index c47ce13..6e16ff9 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java
@@ -89,10 +89,14 @@ public class WALEdit implements Writable, HeapSize {
 
   // TODO: Get rid of this; see HBASE-8457
   public static final byte [] METAFAMILY = Bytes.toBytes("METAFAMILY");
-  static final byte [] METAROW = Bytes.toBytes("METAROW");
-  static final byte[] COMPACTION = Bytes.toBytes("HBASE::COMPACTION");
-  static final byte [] FLUSH = Bytes.toBytes("HBASE::FLUSH");
-  static final byte [] REGION_EVENT = Bytes.toBytes("HBASE::REGION_EVENT");
+  @VisibleForTesting
+  public static final byte [] METAROW = Bytes.toBytes("METAROW");
+  @VisibleForTesting
+  public static final byte[] COMPACTION = Bytes.toBytes("HBASE::COMPACTION");
+  @VisibleForTesting
+  public static final byte [] FLUSH = Bytes.toBytes("HBASE::FLUSH");
+  @VisibleForTesting
+  public static final byte [] REGION_EVENT = Bytes.toBytes("HBASE::REGION_EVENT");
   @VisibleForTesting
   public static final byte [] BULK_LOAD = Bytes.toBytes("HBASE::BULK_LOAD");
 
@@ -334,7 +338,7 @@ public class WALEdit implements Writable, HeapSize {
     return new WALEdit().add(kv); //replication scope null so that this won't be replicated
   }
 
-  private static byte[] getRowForRegion(HRegionInfo hri) {
+  public static byte[] getRowForRegion(HRegionInfo hri) {
     byte[] startKey = hri.getStartKey();
     if (startKey.length == 0) {
       // empty row key is not allowed in mutations because it is both the start key and the end key
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RegionReplicaReplicationEndpoint.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RegionReplicaReplicationEndpoint.java
index 5a3c51d..713442b 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RegionReplicaReplicationEndpoint.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RegionReplicaReplicationEndpoint.java
@@ -368,6 +368,11 @@ public class RegionReplicaReplicationEndpoint extends HBaseReplicationEndpoint {
     }
 
     @Override
+    public boolean keepRegionEvents() {
+      return true;
+    }
+
+    @Override
     public List<Path> finishWritingAndClose() throws IOException {
       finishWriting(true);
       return null;
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/WALSplitter.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/WALSplitter.java
index f50110c..920a9b1 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/WALSplitter.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/WALSplitter.java
@@ -362,6 +362,11 @@ public class WALSplitter {
           editsSkipped++;
           continue;
         }
+        // Don't send Compaction/Close/Open region events to recovered edit type sinks.
+        if (entry.getEdit().isMetaEdit() && !outputSink.keepRegionEvents()) {
+          editsSkipped++;
+          continue;
+        }
         entryBuffers.appendEntry(entry);
         editsCount++;
         int moreWritersFromLastCheck = this.getNumOpenWriters() - numOpenedFilesLastCheck;
@@ -1264,6 +1269,15 @@ public class WALSplitter {
     public boolean flush() throws IOException {
       return false;
     }
+
+    /**
+     * Some WALEdit's contain only KV's for account on what happened to a region.
+     * Not all sinks will want to get those edits.
+     *
+     * @return Return true if this sink wants to get all WALEdit's regardless of if it's a region
+     * event.
+     */
+    public abstract boolean keepRegionEvents();
   }
 
   /**
@@ -1579,6 +1593,11 @@ public class WALSplitter {
       }
     }
 
+    @Override
+    public boolean keepRegionEvents() {
+      return false;
+    }
+
     /**
      * @return a map from encoded region ID to the number of edits written out for that region.
      */
@@ -2025,6 +2044,11 @@ public class WALSplitter {
       return false;
     }
 
+    @Override
+    public boolean keepRegionEvents() {
+      return true;
+    }
+
     void addWriterError(Throwable t) {
       thrown.add(t);
     }
-- 
1.7.9.5

